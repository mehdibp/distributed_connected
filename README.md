# Decentralized RL-based Transmission Power Control in VANETs

This project implements a decentralized Reinforcement Learning (RL) framework to optimize **Transmission Power Control (TPC)** in Vehicular Ad-hoc Networks (VANETs). Using a combination of **SUMO** for traffic dynamics, **OMNeT++** and **Veins** for network simulation, and **TensorFlow** for the RL agents.

## ğŸŒŸ Research Objective
The goal is to maintain a fully connected vehicular network (Global Connectivity) while minimizing energy consumption by dynamically adjusting each vehicle's transmission radius. Each vehicle acts as an independent agent that learns to balance the trade-off between battery life and network connectivity using a custom **Hamiltonian-based reward function**.

## ğŸ›  Tech Stack
- **Simulation Engine:** [OMNeT++ 6.3.0](https://omnetpp.org/)
- **Network Framework:** [INET 4.5.4](https://inet.omnetpp.org/)
- **VANET Framework:** [Veins 5.3.1](https://veins.car2x.org/)
- **Traffic Simulator:** [SUMO 1.22](https://www.eclipse.org/sumo/)
- **RL Brain:** [Python 3.12.8](https://www.python.org/) with [TensorFlow 2.18.0](https://wwww.tensorflow.org/)
- **Interface:** [TraCI](https://sumo.dlr.de/docs/TraCI.html) (Traffic Control Interface)

## ğŸ“‚ Project Structure
```text
VaNet/
â”‚
â”œâ”€â”€ Distributed_Agent/          # Reinforcement Learning Logic (Python)
â”‚   â”œâ”€â”€ Agent.py                # RL Class (DQN/PPO implementation)
â”‚   â”œâ”€â”€ Environment.py          # Wrapper for Network-to-RL state mapping
â”‚   â”œâ”€â”€ Functions.py            # Simulation control & Initializers
â”‚   â””â”€â”€ Analysis.py             # Visualization & Metrics
â”‚
â”œâ”€â”€ Sumo/                       # Traffic Configuration
â”‚   â”œâ”€â”€ maps/                   # Zanjan City .net.xml files
â”‚   â”œâ”€â”€ routes/                 # Vehicle route definitions (.rou.xml)
â”‚   â”œâ”€â”€ polygons/               # Obstacles and buildings (.poly.xml)
â”‚   â”œâ”€â”€ radiation/              # adiation Pattern (.xml)
â”‚   â”œâ”€â”€ physics/                # Physical Layer (.xml)
â”‚   â”œâ”€â”€ SumoScenario/           # Main Files (*.xml)
â”‚   â”‚   â”œâ”€â”€ simulation.sumocfg
â”‚   â”‚   â””â”€â”€ simulation.launchd.xml
â”‚
â”œâ”€â”€ omnetpp/                    # Network Simulation (C++/NED)
â”‚   â”œâ”€â”€ src/                    # Custom RLNode & NetworkServer logic
â”‚   â”œâ”€â”€ ned/                    # Network topology definitions
â”‚   â””â”€â”€ omnetpp.ini             # Physical layer & MAC parameters
â”‚
â”œâ”€â”€ Results/                    # Simulation logs & Excel exports
â”œâ”€â”€ Saved Model/                # Pre-trained .keras models
â””â”€â”€ Agents.ipynb                # Main Execution Notebook
```

## âš™ï¸ Logic & Hamiltonian Reward 

Each agent (vehicle) aims to minimize a local Hamiltonian function:

$$
H = \sum_i H_i = \sum_i \left[ \alpha_{1} k_i^{2} + \alpha_{2} k_i^{3} + \alpha_{3} r_i^{2} + \alpha_{4} \sum_{j(j \ne i)} \frac{A_{ij}}{r_{ij}} \right]
$$

- **State**: Local vehicle density, current transmission power, and neighbor count.
- **Action**: Increase, Decrease, or Maintain transmission radius.
- **Reward**: Based on the reduction of the Hamiltonian value and maintenance of the global connection path.


## ğŸ“Š Performance Metrics
The system evaluates the following:
- **Connectivity Ratio**: Percentage of vehicles connected to the main cluster.
- **Power Consumption**: Average transmission power per node.
- **Convergence**: RL training stability over episodes.
- **Path Availability**: Existence of multi-hop paths between any two nodes.
